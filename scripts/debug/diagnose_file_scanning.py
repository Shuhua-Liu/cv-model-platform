#!/usr/bin/env python3
"""
è¯Šæ–­æ–‡ä»¶æ‰«æé—®é¢˜ - ä¸ºä»€ä¹ˆæ‰¾ä¸åˆ° sd_2_1
ğŸ¯ å…³é”®æ­¥éª¤è¯Šæ–­ï¼š
1. æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
3. æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦æ”¯æŒ
4. æ£€æŸ¥ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤
5. æ£€æŸ¥_analyze_model_fileé€»è¾‘
"""
import sys
from pathlib import Path
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
script_dir = Path(__file__).parent
project_root = script_dir.parent.parent
sys.path.insert(0, str(project_root))
def check_directory_structure(models_root: Path):
   """æ£€æŸ¥ç›®å½•ç»“æ„"""
   print("ğŸ“ æ£€æŸ¥ç›®å½•ç»“æ„...")
   generation_dir = models_root / 'generation'
   if not generation_dir.exists():
       print(f"âŒ generationç›®å½•ä¸å­˜åœ¨: {generation_dir}")
       return {}
   print(f"âœ… generationç›®å½•å­˜åœ¨: {generation_dir}")
   # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«sdçš„ç›®å½•
   target_patterns = ['sd_2_1', 'sd2_1', 'stable_diffusion', 'stable-diffusion']
   found_dirs = {}
   for pattern in target_patterns:
       matching_dirs = list(generation_dir.rglob(f"*{pattern}*"))
       if matching_dirs:
           for dir_path in matching_dirs:
               if dir_path.is_dir():
                   found_dirs[pattern] = dir_path
                   print(f"   ğŸ¯ æ‰¾åˆ°åŒ¹é…ç›®å½• '{pattern}': {dir_path}")
   return found_dirs
def check_files_in_directories(found_dirs: dict):
   """æ£€æŸ¥ç›®å½•ä¸­çš„æ–‡ä»¶"""
   print("\nğŸ“„ æ£€æŸ¥ç›®å½•ä¸­çš„æ–‡ä»¶...")
   # æ”¯æŒçš„æ‰©å±•åï¼ˆæ¥è‡ªModelDetectorï¼‰
   SUPPORTED_EXTENSIONS = {'.pt', '.pth', '.ckpt', '.safetensors', '.bin', '.pkl'}
   all_files = []
   for pattern, directory in found_dirs.items():
       print(f"\nğŸ” æ£€æŸ¥ç›®å½•: {directory}")
       # è·å–æ‰€æœ‰æ–‡ä»¶
       files = list(directory.rglob("*"))
       model_files = [f for f in files if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS]
       print(f"   ğŸ“Š æ€»æ–‡ä»¶æ•°: {len(files)}")
       print(f"   ğŸ¯ æ¨¡å‹æ–‡ä»¶æ•°: {len(model_files)}")
       if model_files:
           print(f"   ğŸ“‹ å‰10ä¸ªæ¨¡å‹æ–‡ä»¶:")
           for i, file_path in enumerate(model_files[:10], 1):
               size_mb = file_path.stat().st_size / (1024 * 1024)
               print(f"      {i}. {file_path.name} ({size_mb:.1f}MB)")
               all_files.append(file_path)
       else:
           print(f"   âŒ æœªæ‰¾åˆ°æ”¯æŒçš„æ¨¡å‹æ–‡ä»¶")
   return all_files
def test_model_detection_logic(models_root: Path, all_files: list):
   """æµ‹è¯•æ¨¡å‹æ£€æµ‹é€»è¾‘"""
   print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹æ£€æµ‹é€»è¾‘...")
   try:
       from src.cv_platform.core.model_detector import ModelDetector
       # åˆ›å»ºæ£€æµ‹å™¨
       detector = ModelDetector(models_root)
       print(f"ğŸ”§ æ£€æµ‹å™¨é…ç½®:")
       print(f"   models_root: {detector.models_root}")
       print(f"   æ”¯æŒçš„æ‰©å±•å: {detector.SUPPORTED_EXTENSIONS}")
       # æ‰‹åŠ¨æµ‹è¯•æ¯ä¸ªæ–‡ä»¶
       detected_models = []
       skipped_files = []
       for file_path in all_files[:20]:  # åªæµ‹è¯•å‰20ä¸ªæ–‡ä»¶
           print(f"\nğŸ“ æµ‹è¯•æ–‡ä»¶: {file_path.name}")
           # æ£€æŸ¥æ‰©å±•å
           if file_path.suffix.lower() not in detector.SUPPORTED_EXTENSIONS:
               print(f"   ğŸš« æ‰©å±•åä¸æ”¯æŒ: {file_path.suffix}")
               skipped_files.append((file_path, "ä¸æ”¯æŒçš„æ‰©å±•å"))
               continue
           try:
               # è°ƒç”¨_analyze_model_file
               model_info = detector._analyze_model_file(file_path)
               if model_info:
                   print(f"   âœ… æ£€æµ‹æˆåŠŸ:")
                   print(f"      åç§°: {model_info.name}")
                   print(f"      ç±»å‹: {model_info.type}")
                   print(f"      æ¡†æ¶: {model_info.framework}")
                   print(f"      æ¶æ„: {model_info.architecture}")
                   print(f"      ç½®ä¿¡åº¦: {model_info.confidence:.2f}")
                   # æ£€æŸ¥ç½®ä¿¡åº¦é˜ˆå€¼
                   if model_info.confidence > 0.5:
                       detected_models.append(model_info)
                       print(f"      ğŸ¯ é€šè¿‡ç½®ä¿¡åº¦é˜ˆå€¼")
                   else:
                       print(f"      ğŸš« ç½®ä¿¡åº¦è¿‡ä½ ({model_info.confidence:.2f} â‰¤ 0.5)")
                       skipped_files.append((file_path, f"ç½®ä¿¡åº¦è¿‡ä½: {model_info.confidence:.2f}"))
               else:
                   print(f"   âŒ æ£€æµ‹å¤±è´¥: _analyze_model_fileè¿”å›None")
                   skipped_files.append((file_path, "_analyze_model_fileè¿”å›None"))
           except Exception as e:
               print(f"   ğŸ’¥ æ£€æµ‹å¼‚å¸¸: {e}")
               skipped_files.append((file_path, f"å¼‚å¸¸: {e}"))
       # æ±‡æ€»ç»“æœ
       print(f"\nğŸ“Š æ£€æµ‹ç»“æœæ±‡æ€»:")
       print(f"   æ£€æµ‹æˆåŠŸ: {len(detected_models)}")
       print(f"   è·³è¿‡æ–‡ä»¶: {len(skipped_files)}")
       # æŸ¥æ‰¾ç›®æ ‡æ¨¡å‹
       target_models = []
       for model in detected_models:
           if any(target in model.name.lower() for target in ['sd_2_1', 'sd2_1']):
               target_models.append(model)
       print(f"   ç›®æ ‡æ¨¡å‹: {len(target_models)}")
       if target_models:
           print(f"\nğŸ¯ æ‰¾åˆ°çš„ç›®æ ‡æ¨¡å‹:")
           for model in target_models:
               print(f"      - {model.name} ({model.confidence:.2f})")
       else:
           print(f"\nâŒ æœªæ‰¾åˆ°ç›®æ ‡æ¨¡å‹ (sd_2_1)")
           # åˆ†æè·³è¿‡çš„æ–‡ä»¶
           print(f"\nğŸ” åˆ†æè·³è¿‡çš„æ–‡ä»¶:")
           sd_related_skipped = []
           for file_path, reason in skipped_files:
               if 'sd_2_1' in str(file_path).lower():
                   sd_related_skipped.append((file_path, reason))
           if sd_related_skipped:
               print(f"   å‘ç° {len(sd_related_skipped)} ä¸ªè¢«è·³è¿‡çš„sd_2_1ç›¸å…³æ–‡ä»¶:")
               for file_path, reason in sd_related_skipped:
                   print(f"      - {file_path}: {reason}")
           else:
               print(f"   æœªå‘ç°sd_2_1ç›¸å…³çš„è¢«è·³è¿‡æ–‡ä»¶")
       return detected_models, skipped_files
   except Exception as e:
       print(f"ğŸ’¥ æµ‹è¯•å¤±è´¥: {e}")
       import traceback
       traceback.print_exc()
       return [], []
def test_walk_directories(models_root: Path):
   """æµ‹è¯•ç›®å½•éå†é€»è¾‘"""
   print(f"\nğŸš¶ æµ‹è¯•ç›®å½•éå†é€»è¾‘...")
   try:
       from src.cv_platform.core.model_detector import ModelDetector
       detector = ModelDetector(models_root)
       # è°ƒç”¨_walk_model_directories
       directories_to_scan = detector._walk_model_directories()
       print(f"ğŸ—‚ï¸ è¦æ‰«æçš„ç›®å½•:")
       for i, directory in enumerate(directories_to_scan, 1):
           print(f"   {i}. {directory}")
       # ç»Ÿè®¡æ¯ä¸ªç›®å½•ä¸‹çš„æ–‡ä»¶
       total_files = 0
       supported_files = 0
       for directory in directories_to_scan:
           if not directory.exists():
               print(f"   âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
               continue
           files = list(directory.rglob("*"))
           dir_files = [f for f in files if f.is_file()]
           dir_supported = [f for f in dir_files if f.suffix.lower() in detector.SUPPORTED_EXTENSIONS]
           total_files += len(dir_files)
           supported_files += len(dir_supported)
           if 'sd_2_1' in str(directory).lower():
               print(f"   ğŸ¯ å…³é”®ç›®å½• {directory}:")
               print(f"      æ€»æ–‡ä»¶: {len(dir_files)}")
               print(f"      æ”¯æŒçš„æ–‡ä»¶: {len(dir_supported)}")
               if dir_supported:
                   print(f"      æ–‡ä»¶åˆ—è¡¨:")
                   for file_path in dir_supported[:5]:
                       print(f"         - {file_path.name}")
       print(f"\nğŸ“Š éå†ç»Ÿè®¡:")
       print(f"   æ‰«æç›®å½•æ•°: {len(directories_to_scan)}")
       print(f"   æ€»æ–‡ä»¶æ•°: {total_files}")
       print(f"   æ”¯æŒçš„æ–‡ä»¶: {supported_files}")
       return directories_to_scan
   except Exception as e:
       print(f"ğŸ’¥ ç›®å½•éå†æµ‹è¯•å¤±è´¥: {e}")
       return []
def provide_fix_suggestions(found_dirs: dict, detected_models: list, skipped_files: list):
   """æä¾›ä¿®å¤å»ºè®®"""
   print(f"\nğŸ’¡ ä¿®å¤å»ºè®®:")
   print("=" * 50)
   if not found_dirs:
       print("1. ğŸ” ç›®å½•é—®é¢˜:")
       print("   - æ£€æŸ¥sd_2_1ç›®å½•æ˜¯å¦å­˜åœ¨äºgenerationç›®å½•ä¸‹")
       print("   - ç¡®è®¤ç›®å½•è·¯å¾„æ˜¯å¦æ­£ç¡®")
       print("   - æ£€æŸ¥ç›®å½•æƒé™")
   if found_dirs and not detected_models:
       print("1. ğŸ“„ æ–‡ä»¶é—®é¢˜:")
       print("   - æ£€æŸ¥ç›®å½•ä¸‹æ˜¯å¦æœ‰æ”¯æŒçš„æ¨¡å‹æ–‡ä»¶ (.pt, .pth, .safetensorsç­‰)")
       print("   - ç¡®è®¤æ–‡ä»¶ä¸æ˜¯ç©ºæ–‡ä»¶æˆ–æŸåæ–‡ä»¶")
       # åˆ†æè·³è¿‡åŸå› 
       skip_reasons = {}
       for _, reason in skipped_files:
           skip_reasons[reason] = skip_reasons.get(reason, 0) + 1
       if skip_reasons:
           print("2. ğŸš« è·³è¿‡åŸå› ç»Ÿè®¡:")
           for reason, count in skip_reasons.items():
               print(f"   - {reason}: {count} ä¸ªæ–‡ä»¶")
   print(f"\nğŸ”§ å¯èƒ½çš„ä¿®å¤æ–¹æ³•:")
   print("1. é™ä½ç½®ä¿¡åº¦é˜ˆå€¼:")
   print("   åœ¨ ModelDetector._perform_model_scan() ä¸­")
   print("   å°† 'confidence > 0.5' æ”¹ä¸º 'confidence > 0.3'")
   print()
   print("2. å¢åŠ è°ƒè¯•æ—¥å¿—:")
   print("   åœ¨ _analyze_model_file ä¸­æ·»åŠ  logger.debug è¾“å‡º")
   print()
   print("3. æ£€æŸ¥_generate_model_nameé€»è¾‘:")
   print("   ç¡®ä¿ç”Ÿæˆçš„æ¨¡å‹åç§°åŒ…å«'sd_2_1'")
def main():
   """ä¸»è¯Šæ–­å‡½æ•°"""
   print("ğŸš¨ è¯Šæ–­æ–‡ä»¶æ‰«æé—®é¢˜")
   print("=" * 60)
   print("é—®é¢˜: æœ€åˆæ‰«æå°±æ‰¾ä¸åˆ° sd_2_1 æ¨¡å‹")
   print("ç›®æ ‡: è¯Šæ–­æ–‡ä»¶æ‰«æçš„æ¯ä¸ªæ­¥éª¤\n")
   try:
       # è·å–æ¨¡å‹æ ¹ç›®å½•
       from src.cv_platform.core.config_manager import get_config_manager
       config_manager = get_config_manager()
       models_root = config_manager.get_models_root()
       print(f"ğŸ“ æ¨¡å‹æ ¹ç›®å½•: {models_root}")
       # 1. æ£€æŸ¥ç›®å½•ç»“æ„
       found_dirs = check_directory_structure(models_root)
       if not found_dirs:
           print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³ç›®å½•ï¼Œè¯·æ£€æŸ¥ç›®å½•ç»“æ„")
           return
       # 2. æ£€æŸ¥æ–‡ä»¶
       all_files = check_files_in_directories(found_dirs)
       if not all_files:
           print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")
           return
       # 3. æµ‹è¯•ç›®å½•éå†
       directories_to_scan = test_walk_directories(models_root)
       # 4. æµ‹è¯•æ¨¡å‹æ£€æµ‹é€»è¾‘
       detected_models, skipped_files = test_model_detection_logic(models_root, all_files)
       # 5. æä¾›ä¿®å¤å»ºè®®
       provide_fix_suggestions(found_dirs, detected_models, skipped_files)
       print(f"\nğŸ¯ è¯Šæ–­å®Œæˆ!")
   except Exception as e:
       print(f"ğŸ’¥ è¯Šæ–­å¤±è´¥: {e}")
       import traceback
       traceback.print_exc()
if __name__ == "__main__":
   try:
       main()
   except KeyboardInterrupt:
       print("\n\nğŸ‘‹ è¯Šæ–­è¢«ç”¨æˆ·ä¸­æ–­")
   except Exception as e:
       print(f"\n\nğŸ’¥ è¯Šæ–­è¿‡ç¨‹ä¸­å‡ºç°æœªé¢„æœŸçš„é”™è¯¯: {e}")
       import traceback
       traceback.print_exc()
